{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class SimpleLR:\n",
    "    \n",
    "    #class constructor\n",
    "    def __init__(self):\n",
    "        # learning_rate is a alpha\n",
    "        self.learning_rate = 0.01\n",
    "        self.epoch = 10000\n",
    "        \"\"\"\n",
    "        epoch = 10000\n",
    "        \n",
    "        when alpha = 0.01\n",
    "        theta_0 = 0 and theta_1 = 1 -->82.48793982639448\n",
    "        theta_0 = 0.1 and theta_1 = 1 --> 82.5805613030006\n",
    "        theta_0 = 0.5 and theta_1 --> 82.93816210555873\n",
    "        \n",
    "        alpha= 0.1, theta_0 = 0 and theta_1 = 1--> 55.636516896595786\n",
    "        \n",
    "        when apha = 0.001\n",
    "        theta_0 = 0.5 and theta_1 = 0.75 --> 77.4370554191209\n",
    "        theta_0 = 1 and theta_1 = 0.75 --> 76.84425458676488\n",
    "        theta_0 = 0 and theta_1 = 0.75 -->77.93696614406973\n",
    "        theta_0 = 0 and theta_1 = 1.5 -->77.93696614406973\n",
    "        theta_0 = 0 and theta_1 = 1.5 --> 37.23854408494107\n",
    "        \n",
    "        #best one\n",
    "        theta_0 = 0 and theta_1 = 1 --> 79.67312639225544\n",
    "        \n",
    "        when alpha = 0.0001\n",
    "       theta_0 = 0, theta_1 = 1 -->3.814907292161518\n",
    "\n",
    "         \"\"\"\n",
    "        self.theta_0 = 0.5\n",
    "        self.theta_1 = 1\n",
    "        \n",
    "        \n",
    "     # fuction for display csv file\n",
    "    def display_data(self):\n",
    "       \n",
    "       # Exception handling for file \n",
    "        try:\n",
    "           # for user input file name\n",
    "           self.file = input(\"\\n Enter training_file name:-\")\n",
    "           # read csv file\n",
    "           self.df = pd.read_csv(self.file)\n",
    "\n",
    "           # for user input file name\n",
    "           self.file = input(\"\\n Enter test_file name:-\")\n",
    "\n",
    "           # read csv file\n",
    "           self.df_1 = pd.read_csv(self.file)\n",
    " \n",
    "       \n",
    "        # if file not found the error\n",
    "        except OSError as e:\n",
    "           # print exception\n",
    "           print(\"File not found\")\n",
    "  \n",
    "\n",
    "    \"\"\"Handling missing data\"\"\"\n",
    "    def handling_missing_data(self):\n",
    "       \n",
    "       # check data type of all variable\n",
    "        print(\"\\nCheck dtypes for training datase\\n\",self.df.dtypes)\n",
    "       \n",
    "       # check for null value\n",
    "        print(\"\\nChecking Null Value\\n\",self.df.isnull().sum())\n",
    "\n",
    "       # replacing missing values with mean\n",
    "\n",
    "        self.df['x'].replace(np.NaN,self.df['x'].mean(), inplace = True)\n",
    "       \n",
    "        self.df['y'].replace(np.NaN,self.df['y'].mean(), inplace = True)\n",
    "       ##########################################3\n",
    "       # check data type of all variable\n",
    "        print(\"\\nCheck dtypes for test datase\\n\",self.df_1.dtypes)\n",
    "       \n",
    "       # check for null value\n",
    "        print(\"\\nChecking Null Value\\n\",self.df_1.isnull().sum())\n",
    "\n",
    "       # replacing missing values with mean\n",
    "\n",
    "        self.df_1['x'].replace(np.NaN,self.df_1['x'].mean(), inplace = True)\n",
    "        self.df_1['y'].replace(np.NaN,self.df_1['y'].mean(), inplace = True)\n",
    "       \n",
    "       \n",
    "    \"\"\"Feature scaling\"\"\"  \n",
    "    def feature_scaling(self):\n",
    "       # Simple feature scaling\n",
    "        self.df[\"x\"] = self.df[\"x\"]/self.df[\"x\"].max()\n",
    "        self.df[\"y\"]= self.df[\"y\"]/self.df[\"y\"].max()\n",
    "        print(\"Simple feature scaling\")\n",
    "\n",
    "    def split(self):\n",
    "        print(\"Convert pandas datafrem into numpy\")\n",
    "        x_train_data = np.array(self.df.x[:len(self.df.x)])   \n",
    "        y_train_data = np.array(self.df.y[:len(self.df.y)])\n",
    "#         print(\"x test\",x_train_data)\n",
    "#         print(\"Y test\",y_train_data)\n",
    "        x_test_data = np.array(self.df_1.x[:len(self.df_1.x)])\n",
    "        y_test_data = np.array(self.df_1.y[:len(self.df_1.y)])\n",
    "       \n",
    "        return x_train_data, y_train_data, x_test_data, y_test_data\n",
    "    \n",
    "    def gradient_descent(self,x_train_data, y_train_data):\n",
    "        cost = 0\n",
    "            \n",
    "        fig = plt.figure()\n",
    "        fig, (ax1, ax2, ax3,ax4) = plt.subplots(nrows=4, ncols=1, figsize=(5, 20))\n",
    "    \n",
    "        size = len(x_train_data)\n",
    "        vector = np.ones(size)\n",
    "        hypo_1 = 0.0\n",
    "        hypo_2 = 0.0\n",
    "        cost_temp = 0.0\n",
    "        for iteration in range(self.epoch):\n",
    "            for row in range(size):\n",
    "                hypo = ((self.theta_0 * vector[row])  + (self.theta_1 * x_train_data[row]))\n",
    "                hypo_1 += hypo - y_train_data[row]\n",
    "                hypo_2 += (hypo - y_train_data[row]) * x_train_data[row]\n",
    "                cost += hypo - y_train_data[row]\n",
    "\n",
    "            cost_temp +=(hypo - y_train_data[row]) ** 2 \n",
    "            cost = (1/2 * size)* cost_temp\n",
    "            self.theta_0 = self.theta_0 -((self.learning_rate/ size) * hypo_1)\n",
    "            self.theta_1 = self.theta_1 -((self.learning_rate/ size)* hypo_2)\n",
    "        \n",
    "#         for counter in range(0, self.epoch):\n",
    "            if(iteration%100 == 0):\n",
    "                # plt.plot(counter,loss_error_sum, marker='x', color='r')\n",
    "                ax1.plot(iteration,self.theta_0,marker='o',color='r')\n",
    "                ax1.set_title('iteration vs theta 0')\n",
    "                ax2.plot(iteration,self.theta_1,marker='8',color='g')\n",
    "                ax2.set_title('iteration vs theta 1')\n",
    "                ax3.plot(iteration,cost,marker='*',color='b')\n",
    "                ax3.set_title('iteration vs cost')\n",
    "                ax4.plot(self.theta_0,self.theta_1,marker = 'x', color='black')\n",
    "                ax4.set_title('theta_0 vs theta_1')\n",
    "            if(cost<=0.00009): \n",
    "                break\n",
    "\n",
    "        plt.subplots_adjust(hspace=1)\n",
    "        plt.show()\n",
    "        print(\"iteration = {} and cost function = {}\".format(iteration, cost))\n",
    "            \n",
    "        return [self.theta_0,self.theta_1], cost\n",
    "        \n",
    "    # y_prediction for test dataset\n",
    "    def predict (self, x_test_data,theta_00):\n",
    "        \n",
    "        n = len(x_test_data)\n",
    "        y_predict = [None]*n\n",
    "        vector = np.ones(n)\n",
    "        for row in range (n):\n",
    "            y_predict[row] = theta_00[0] * vector[row]  + theta_00[1] * x_test_data[row] \n",
    "        # y prediction for test\n",
    "        return y_predict\n",
    "    \n",
    "    # y_prediction for test dataset\n",
    "    def predict_new(self, x_train_data,theta_00):\n",
    "        \n",
    "        n = len(x_train_data)\n",
    "        y_predict_train = [None]*n\n",
    "        vector = np.ones(n)\n",
    "        for row in range (n):\n",
    "            y_predict_train[row] = theta_00[0] * vector[row]  + theta_00[1] * x_train_data[row] \n",
    "            #for train\n",
    "        return y_predict_train\n",
    "   \n",
    "     \n",
    "    def accuracy(self, y_test_data, y_predict):\n",
    "         \n",
    "        print(\"y\", y_test_data.shape)\n",
    "        total_error = 0\n",
    "        for i in range(0, len(y_test_data)):\n",
    "            total_error += abs((y_predict[i] - y_test_data[i]) / y_test_data[i])\n",
    "        total_error = (total_error / len(y_test_data))\n",
    "        accuracy = 1 - total_error\n",
    "        return accuracy * 100\n",
    "\n",
    "    # scatter plot on x_test y_test data vs x_test y_pre      \n",
    "    def graph(self, x_train_data, y_train_data, y_predict): \n",
    "        print(len(x_train_data))\n",
    "        print(len(y_train_data))\n",
    "        print(len(y_predict))\n",
    "        \n",
    "        plt.scatter(x_train_data, y_train_data , color = 'b', label = \"train data set\")\n",
    "        plt.plot(x_train_data, y_predict, color = 'r', label = \"predicted value\")\n",
    "        plt.title(\"Train data\")\n",
    "#         plt.subplot(2,2,1)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    # scatter plot on x_test_data, y_test_data data vs x_test y_pre   \n",
    "    def plotgraph(self, x_test_data, y_test_data, y_predict):\n",
    "        print(len(x_test_data))\n",
    "        print(len(y_test_data))\n",
    "        print(len(y_predict))\n",
    "        \n",
    "        plt.scatter(x_test_data, y_test_data , color = 'g', label = \"test data\")\n",
    "        plt.plot(x_test_data, y_predict,color = 'r', label = \"predicted value\")\n",
    "\n",
    "        plt.title(\"Test data\")\n",
    "#         plt.subplot(2,2,1)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "obj = SimpleLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Show dataset details:----------\n",
      "\n",
      " Enter training_file name:-cfg\n",
      "File not found\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------Show dataset details:----------\")\n",
    "obj.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Handling Missing Data:----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SimpleLR' object has no attribute 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-566216ef83e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n----------Handling Missing Data:----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandling_missing_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-25e5827b1753>\u001b[0m in \u001b[0;36mhandling_missing_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m        \u001b[0;31m# check data type of all variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCheck dtypes for training datase\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m        \u001b[0;31m# check for null value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SimpleLR' object has no attribute 'df'"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------Handling Missing Data:----------\")\n",
    "obj.handling_missing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.feature_scaling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data, y_train_data, x_test_data, y_test_data = obj.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 , cost = obj.gradient_descent(x_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = obj.predict (x_test_data,theta_0)\n",
    "# print(\"Prediction\", y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = obj.accuracy(y_test_data, y_predict)\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = obj.predict_new(x_train_data,theta_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data set\n",
    "obj.graph(x_train_data, y_train_data , yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test dataset\n",
    "obj.plotgraph( x_test_data, y_test_data, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj.graph3(theta_0, cost)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
