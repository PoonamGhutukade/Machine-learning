{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas.api.types as ptypes\n",
    "    \n",
    "#Scikit-learn for one hot encoding\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\"\"\"Build a predictive linear regression model for given dataset,\n",
    "given --------temperature, humidity, wind speed , wind bearing, visibility, pressure  \n",
    "predict ------apparent temperature\n",
    "\"\"\"\n",
    "class DataPreprocessing:\n",
    "    \n",
    "    #class constructor\n",
    "    def __init__(self):\n",
    "        # learning_rate is a alpha\n",
    "        self.learning_rate = 0.01\n",
    "        self.epoch = 100\n",
    "        self.theta_0 = 0.5\n",
    "        self.theta_1 = 1\n",
    "        \n",
    "    # Display datafile\n",
    "    def display_data(self):\n",
    "        self.file = input(\"Enter the file name:\")\n",
    "\n",
    "        file_exist = os.path.exists(self.file)\n",
    "        # Exception Handling for file\n",
    "        try:\n",
    "            f = open(self.file, 'rb')\n",
    "            # read csv file\n",
    "            self.df = pd.read_csv(self.file)\n",
    "#             print(\"\\n\",self.df)\n",
    "            # Head and tail functions show fist and last 5 rows of dataset \n",
    "            print(\"\\nHead \\n:\", self.df.head())\n",
    "            print(\"\\nTail \\n\", self.df.tail())\n",
    "            print(\"\\nType of DF: \",type(self.df))\n",
    "            # descibe dataframe\n",
    "            print(\"\\nDescribe Data: \\n\",self.df.describe())\n",
    "            print(\"\\nColumns are: \\n\",self.df.columns)\n",
    "            print(\"\\n Shape of dataset(rows and columns): \\n\", self.df.shape)\n",
    "            \n",
    "        except FileNotFoundError as ex:\n",
    "            print(\"\\nInvalid file Name\",ex)\n",
    "        \n",
    "    \"\"\"Handling Missing Data\"\"\"\n",
    "    def missing_data(self):\n",
    "        # drop unrequired ddata columns\n",
    "        #self.df = self.df.drop()\n",
    "        \"\"\"Index( 'Temperature (C)',\n",
    "       'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)',\n",
    "       'Wind Bearing (degrees)', 'Visibility (km)', \n",
    "       'Pressure (millibars)',)\"\"\"\n",
    "     \n",
    "\n",
    "        print(\"\\nDrop unwanted columns\")\n",
    "        self.df  = self.df.loc[:,['Temperature (C)','Humidity','Wind Speed (km/h)','Wind Bearing (degrees)',\n",
    "                                   'Visibility (km)', 'Pressure (millibars)','Apparent Temperature (C)', ]]\n",
    "        print(\"\\n\",self.df.head())\n",
    "        print(\"\\nData type of each column:\\n\",self.df.dtypes)\n",
    "        \n",
    "        #check null values in each column\n",
    "        check = self.df.isnull().sum()\n",
    "        print(\"\\nNull values in dataset:\\n\",check)\n",
    "#         if self.df.empty == True:\n",
    "#             print(\"Not a null value\")\n",
    "#         else:\n",
    "#             # replace null values with mean\n",
    "#             self.df.replace(np.NaN, self.df.mean(), inplace = True)\n",
    "#             print(\"\\n\",self.df.head())\n",
    "            \n",
    "        # rename columns \n",
    "        \n",
    "        self.df.rename(columns={'Apparent Temperature (C)':'App_temp','Humidity':'Humi'}, inplace=True)\n",
    "        print(\"\\nRename Columns:\\n\",self.df.head())\n",
    "        \n",
    "        \n",
    "    # check outlieers for columns\n",
    "    def check_outliers(self):\n",
    "#         self.df.boxplot()\n",
    "#         show()     \n",
    "        sb.boxplot(self.df['App_temp'])\n",
    "        plt.title(\"Temprature outliers\")\n",
    "        plt.show()\n",
    "        \n",
    "        sb.boxplot(self.df['Humi'])\n",
    "        plt.title(\"Humidity outliers \")\n",
    "        plt.show()\n",
    "        \n",
    "    # remove outliers\n",
    "    def remove_outlier(self):\n",
    "        low = .05\n",
    "        high = .95\n",
    "        quant_df = self.df.quantile([low, high])\n",
    "        for name in list(self.df.columns):\n",
    "            if ptypes.is_numeric_dtype(self.df[name]):\n",
    "                self.df = self.df[(self.df[name] > quant_df.loc[low, name]) & (self.df[name] < quant_df.loc[high, name])]\n",
    "        sb.boxplot(self.df)  \n",
    "\n",
    "        \n",
    "    def check_skew(self):\n",
    "        \"\"\"If skewness value lies above +1 or below -1, data is highly skewed. \n",
    "        If it lies between +0.5 to -0.5, it is moderately skewed. \n",
    "        If the value is 0, then the data is symmetric\"\"\"\n",
    "        \n",
    "        print(\"\\n Mean: \\n\",self.df.mean(), \"\\n\\nSkew : \\n\",self.df.skew(), \"\\n\\nMedian: \\n\", self.df.median())\n",
    "        sb.distplot(self.df['App_temp'])\n",
    "        plt.show()\n",
    "        \n",
    "        sb.distplot(self.df['Humi'])\n",
    "        plt.show()\n",
    "        mean_col1 = self.df['App_temp'].mean()\n",
    "        medi_col1 = self.df['App_temp'].median()\n",
    "        \n",
    "        mean_col2 = self.df['Humi'].mean()\n",
    "        modi_col2 = self.df['Humi'].median()\n",
    "        \n",
    "        print(\"\\nFor Apparent Temperature (C):\")\n",
    "        if mean_col1 <= medi_col1:\n",
    "            print(\"Left skew\")\n",
    "        elif mean_col1 >= medi_col1: \n",
    "            print(\"Right skew\")\n",
    "        else:\n",
    "            print(\"data is symmetric\")\n",
    "            \n",
    "        print(\"\\nFor Humidity :\")\n",
    "        if mean_col2 <= modi_col2:\n",
    "            print(\"Left skew\")\n",
    "        elif mean_col2 >= modi_col2: \n",
    "            print(\"Right skew\")\n",
    "        else:\n",
    "            print(\"data is symmetric\")\n",
    "            \n",
    "    def feature_scaling(self):       \n",
    "        print(\"\\n By Z score Method(Standerdization)  \")\n",
    "        \n",
    "        self.df = np.divide((self.df - self.df.mean()), self.df.std())\n",
    "#         self.df['App_temp'] = np.divide((self.df['App_temp'] - self.df['App_temp'].mean()), self.df['App_temp'].std())\n",
    "#         self.df['Humi'] =  np.divide((self.df['Humi'] - self.df['Humi'].mean()),self.df['Humi'].std())\n",
    "        print(self.df.head())\n",
    "    \n",
    "    def split(self):\n",
    "        train_per = int(0.70*len(self.df))\n",
    "        test_per = len(self.df)-train_per\n",
    "#         X_train_set = self.df.head(train_per)\n",
    "#         Y_train_set = self.df.tail(test_per)\n",
    "       \n",
    "        # display data\n",
    "        print(\"\\nTraining set\")\n",
    "        print(train_per)\n",
    "        print(\"\\nTest data set\")\n",
    "        print(test_per)\n",
    "       \n",
    "        print(\"Convert pandas dataframe into numpy\")\n",
    "       \n",
    "        x_train_data = np.array(self.df.App_temp[:train_per])   \n",
    "        y_train_data = np.array(self.df.Humi[:train_per])\n",
    "\n",
    "        x_test_data = np.array(self.df.App_temp[:test_per])\n",
    "        y_test_data = np.array(self.df.Humi[:test_per])\n",
    "       \n",
    "      \n",
    "        return x_train_data,y_train_data,x_test_data,y_test_data\n",
    "    \n",
    "    def gradient_descent(self,x_train_data, y_train_data):\n",
    "        cost = 0\n",
    "            \n",
    "        fig = plt.figure()\n",
    "        fig, (ax1, ax2, ax3,ax4) = plt.subplots(nrows=4, ncols=1, figsize=(5, 20))\n",
    "    \n",
    "        size = len(x_train_data)\n",
    "        vector = np.ones(size)\n",
    "        hypo_1 = 0.0\n",
    "        hypo_2 = 0.0\n",
    "        cost_temp = 0.0\n",
    "        for iteration in range(self.epoch):\n",
    "            for row in range(size):\n",
    "                hypo = ((self.theta_0 * vector[row])  + (self.theta_1 * x_train_data[row]))\n",
    "                hypo_1 += hypo - y_train_data[row]\n",
    "                hypo_2 += (hypo - y_train_data[row]) * x_train_data[row]\n",
    "                cost += hypo - y_train_data[row]\n",
    "\n",
    "            cost_temp +=(hypo - y_train_data[row]) ** 2 \n",
    "            cost = (1/2 * size)* cost_temp\n",
    "            self.theta_0 = self.theta_0 -((self.learning_rate/ size) * hypo_1)\n",
    "            self.theta_1 = self.theta_1 -((self.learning_rate/ size)* hypo_2)\n",
    "        \n",
    "#         for counter in range(0, self.epoch):\n",
    "            if(iteration%100 == 0):\n",
    "                # plt.plot(counter,loss_error_sum, marker='x', color='r')\n",
    "                ax1.plot(iteration,self.theta_0,marker='o',color='r')\n",
    "                ax1.set_title('iteration vs theta 0')\n",
    "                ax2.plot(iteration,self.theta_1,marker='8',color='g')\n",
    "                ax2.set_title('iteration vs theta 1')\n",
    "                ax3.plot(iteration,cost,marker='*',color='b')\n",
    "                ax3.set_title('iteration vs cost')\n",
    "                ax4.plot(self.theta_0,self.theta_1,marker = 'x', color='black')\n",
    "                ax4.set_title('theta_0 vs theta_1')\n",
    "            if(cost<=0.00009): \n",
    "                break\n",
    "\n",
    "        plt.subplots_adjust(hspace=1)\n",
    "        plt.show()\n",
    "        print(\"iteration = {} and cost function = {}\".format(iteration, cost))\n",
    "            \n",
    "        return [self.theta_0,self.theta_1], cost\n",
    "        \n",
    "    # y_prediction for test dataset\n",
    "    def predict (self, x_test_data,theta_00):\n",
    "        \n",
    "        n = len(x_test_data)\n",
    "        y_predict = [None]*n\n",
    "        vector = np.ones(n)\n",
    "        for row in range (n):\n",
    "            y_predict[row] = theta_00[0] * vector[row]  + theta_00[1] * x_test_data[row] \n",
    "        # y prediction for test\n",
    "        return y_predict\n",
    "    \n",
    "    # y_prediction for test dataset\n",
    "    def predict_new(self, x_train_data,theta_00):\n",
    "        \n",
    "        n = len(x_train_data)\n",
    "        y_predict_train = [None]*n\n",
    "        vector = np.ones(n)\n",
    "        for row in range (n):\n",
    "            y_predict_train[row] = theta_00[0] * vector[row]  + theta_00[1] * x_train_data[row] \n",
    "            #for train\n",
    "        return y_predict_train\n",
    "   \n",
    "     \n",
    "    def accuracy(self, y_test_data, y_predict):\n",
    "         \n",
    "        print(\"y\", y_test_data.shape)\n",
    "        total_error = 0\n",
    "        for i in range(0, len(y_test_data)):\n",
    "            total_error += abs((y_predict[i] - y_test_data[i]) / y_test_data[i])\n",
    "        total_error = (total_error / len(y_test_data))\n",
    "        accuracy = 1 - total_error\n",
    "        return accuracy * 100\n",
    "\n",
    "    # scatter plot on x_test y_test data vs x_test y_pre      \n",
    "    def graph(self, x_train_data, y_train_data, y_predict): \n",
    "        print(len(x_train_data))\n",
    "        print(len(y_train_data))\n",
    "        print(len(y_predict))\n",
    "        \n",
    "        plt.scatter(x_train_data, y_train_data , color = 'b', label = \"train data set\")\n",
    "        plt.plot(x_train_data, y_predict, color = 'r', label = \"predicted value\")\n",
    "        plt.title(\"Train data\")\n",
    "#         plt.subplot(2,2,1)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    # scatter plot on x_test_data, y_test_data data vs x_test y_pre   \n",
    "    def plotgraph(self, x_test_data, y_test_data, y_predict):\n",
    "        print(len(x_test_data))\n",
    "        print(len(y_test_data))\n",
    "        print(len(y_predict))\n",
    "        \n",
    "        plt.scatter(x_test_data, y_test_data , color = 'g', label = \"test data\")\n",
    "        plt.plot(x_test_data, y_predict,color = 'r', label = \"predicted value\")\n",
    "\n",
    "        plt.title(\"Test data\")\n",
    "#         plt.subplot(2,2,1)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "# class Object created to call its method\n",
    "obj = DataPreprocessing()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the file name:fgh\n",
      "\n",
      "Invalid file Name [Errno 2] No such file or directory: 'fgh'\n"
     ]
    }
   ],
   "source": [
    "obj.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Drop unwanted columns\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataPreprocessing' object has no attribute 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d293c4a7bbd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-4fcbbeec4b86>\u001b[0m in \u001b[0;36mmissing_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDrop unwanted columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         self.df  = self.df.loc[:,['Temperature (C)','Humidity','Wind Speed (km/h)','Wind Bearing (degrees)',\n\u001b[0m\u001b[1;32m     59\u001b[0m                                    'Visibility (km)', 'Pressure (millibars)','Apparent Temperature (C)', ]]\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataPreprocessing' object has no attribute 'df'"
     ]
    }
   ],
   "source": [
    "obj.missing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.check_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Outliers are removed\")\n",
    "# obj.remove_outlier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.check_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Check skewness for dataset columns:\")\n",
    "obj.check_skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Remove skewness using cuberoot method\")\n",
    "# obj.remove_skew_sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj.feature_scaling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data, y_train_data, x_test_data, y_test_data = obj.split()\n",
    "# print(x_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 , cost = obj.gradient_descent(x_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = obj.predict (x_test_data,theta_0)\n",
    "# print(\"Prediction\", y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = obj.accuracy(y_test_data, y_predict)\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = obj.predict_new(x_train_data,theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data set\n",
    "obj.graph(x_train_data, y_train_data , yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataset\n",
    "obj.plotgraph( x_test_data, y_test_data, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
