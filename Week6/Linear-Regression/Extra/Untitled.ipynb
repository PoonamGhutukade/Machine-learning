{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "#Scikit-learn for one hot encoding\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class SimpleLR:\n",
    "    \n",
    "    #class constructor\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.001\n",
    "        self.epoch = 10000\n",
    "        self.theta_0 = 0.5\n",
    "        self.theta_1 = 0.75\n",
    "        \n",
    "        \n",
    "     # fuction for display csv file\n",
    "    def display_data(self):\n",
    "       \n",
    "       # Exception handling for file \n",
    "        try:\n",
    "            # for user input file name\n",
    "            self.file = input(\"\\n Enter file name:-\")\n",
    "            # read csv file\n",
    "            self.df = pd.read_csv(self.file)\n",
    "            # print(\"\\n Read file\",df.head(15))\n",
    "#           print(self.df)\n",
    "            print(\"\\nType of DF: \",type(self.df))\n",
    "            print(\"\\nData type of each column:\\n\",self.df.dtypes)\n",
    "        #   descibe dataframe\n",
    "            print(\"\\nDescribe Data: \\n\",self.df.describe())\n",
    "            \n",
    "            \n",
    "            self.df = input(\"\\n Enter file name:-\")\n",
    "\n",
    "            # read csv file\n",
    "            self.df_1 = pd.read_csv(self.file)\n",
    "            print(\"\\nType of DF for test dataset: \",type(self.df_1))\n",
    "            print(\"\\nData type of each column for test dataset:\\n\",self.df_1.dtypes)\n",
    "        #   descibe dataframe\n",
    "            print(\"\\nDescribe Data for test dataset: \\n\",self.df_1.describe())\n",
    "            \n",
    "           # print(\"\\n Read file\",df.head(15))\n",
    "#            print(self.df_1)\n",
    "       \n",
    "        # if file not found the error\n",
    "        except OSError as e:\n",
    "           # print exception\n",
    "           print(\"File not found\")\n",
    "  \n",
    "\n",
    "    \"\"\"Handling missing data\"\"\"\n",
    "    def handling_missing_data(self):\n",
    "#         # check data type of all variable for train dataset\n",
    "#         print(\"\\n\",self.df.dtypes)\n",
    "        \n",
    "        # check for null value\n",
    "        print(\"Null values in dataset:\\n\",self.df.isnull().sum())\n",
    "        \n",
    "        # replacing missing values with mean\n",
    "\n",
    "        self.df['x'].replace(np.NaN,self.df['x'].mean(), inplace = True)\n",
    "        self.df['y'].replace(np.NaN,self.df['y'].mean(), inplace = True)\n",
    "        # print file\n",
    "#         print(self.df)\n",
    "\n",
    "       ###################################\n",
    "    \n",
    "       # check data type of all variable for test dataset\n",
    "        print(\"\\n\",self.df_1.dtypes)\n",
    "       \n",
    "       # check for null value\n",
    "        print(\"\\n\\n\",self.df_1.isnull().sum())\n",
    "\n",
    "       # replacing missing values with mean\n",
    "\n",
    "        self.df_1['x'].replace(np.NaN,self.df_1['x'].mean(), inplace = True)\n",
    "        self.df_1['y'].replace(np.NaN,self.df_1['y'].mean(), inplace = True)\n",
    "       # print file\n",
    "        print(self.df_1)\n",
    "       \n",
    "       \n",
    "\n",
    "          \n",
    "    \"\"\"Feature scaling\"\"\"  \n",
    "    def feature_scaling(self):\n",
    "       # Simple feature scaling\n",
    "        self.df[\"x\"] = self.df[\"x\"]/self.df[\"x\"].max()\n",
    "        self.df[\"y\"]= self.df[\"y\"]/self.df[\"y\"].max()\n",
    "        print(\"Simple feature scaling\")\n",
    "#         print(self.df)\n",
    "       #         # Min-Max\n",
    "#         self.df[\"Age\"] = (self.df[\"Age\"]-self.df[\"Age\"].min())/(self.df[\"Age\"].max()-self.df[\"Age\"].min())\n",
    "#         self.df[\"Salary\"] = (self.df[\"Salary\"]-self.df[\"Salary\"].min())/(self.df[\"Salary\"].max()-self.df[\"Salary\"].min())\n",
    "#         print(\"Min-max\")\n",
    "#         print(self.df)\n",
    "       \n",
    "#         # Z-Score\n",
    "    def split(self):\n",
    "        print(\"Convert pandas datafrem into numpy\")\n",
    "        x_train_data = np.array(self.df.x[:len(self.df.x)])   \n",
    "        y_train_data = np.array(self.df.y[:len(self.df.y)])\n",
    "#         print(\"x test\",x_train_data)\n",
    "#         print(\"Y test\",y_train_data)\n",
    "        x_test_data = np.array(self.df_1.x[:len(self.df_1.x)])\n",
    "        y_test_data = np.array(self.df_1.y[:len(self.df_1.y)])\n",
    "#         print(\"x test\",x_test_data)\n",
    "       \n",
    "        return x_train_data, y_train_data, x_test_data, y_test_data\n",
    "    \n",
    "    def gradient_descent(self,x_train_data, y_train_data):\n",
    "        n = len(x_train_data)\n",
    "        vector = np.ones(n)\n",
    "        size = len(x_train_data)\n",
    "        hypo_1 = 0.0\n",
    "        hypo_2 = 0.0\n",
    "        for i in range(self.epoch):\n",
    "            for row in range(size):\n",
    "                hypo_1 +=((self.theta_0 * vector[row])  + (self.theta_1 * x_train_data[row]))- y_train_data[row]\n",
    "                hypo_2 +=(((self.theta_0 *  vector[row]) + (self.theta_1 * x_train_data[row])) - y_train_data[row]) * x_train_data[row]\n",
    "                \n",
    "#                 print(\".........\",hypo_1)\n",
    "#                 print(\"$$$$$$$$4\",hypo_2)\n",
    "            self.theta_0 = self.theta_0 -((self.learning_rate/ size) * hypo_1)\n",
    "            self.theta_1 = self.theta_1 -((self.learning_rate/ size)* hypo_2)\n",
    "#             print(self.theta_0)\n",
    "#             print(self.theta_1)\n",
    "#         return [self.theta_0,self.theta_1]\n",
    "        return [self.theta_0,self.theta_1]\n",
    "       \n",
    "    def predict (self, x_test_data,theta_00):\n",
    "        \n",
    "        n = len(x_test_data)\n",
    "        y_predict = [None]*n\n",
    "        vector = np.ones(n)\n",
    "        for row in range (n):\n",
    "            y_predict[row] = theta_00[0] * vector[row]  + theta_00[1] * x_test_data[row] \n",
    "        return y_predict\n",
    "   \n",
    "\n",
    "    def accuracy(self, y_test_data, y_predict):\n",
    "         \n",
    "        print(\"y\", y_test_data.shape)\n",
    "        total_error = 0\n",
    "        for i in range(0, len(y_test_data)):\n",
    "            total_error += abs((y_predict[i] - y_test_data[i]) / y_test_data[i])\n",
    "        total_error = (total_error / len(y_test_data))\n",
    "        accuracy = 1 - total_error\n",
    "        return accuracy * 100\n",
    "    \n",
    "    def plot(self):\n",
    "        \n",
    "        \n",
    "        sb.scatterplot(data=self.df, x=\"theta_00\", y=\"self.epoch\")\n",
    "\n",
    "        #  title for scatter plot\n",
    "        plt.title(\"SCATTER PLOT\")\n",
    "\n",
    "        # show scatter plot\n",
    "        plt.show()\n",
    "        \n",
    "# def main():\n",
    "#     train_data = pd.read_csv(\"train.csv\")\n",
    "#     test_data = pd.read_csv(\"test.csv\")\n",
    "   \n",
    "#     x_train_data = train_data.x\n",
    "#     y_train_data = train_data.y\n",
    "#     x_test_data = test_data.x\n",
    "#     y_test_data = test_data.y\n",
    "   \n",
    "obj = SimpleLR()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
