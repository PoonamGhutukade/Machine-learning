{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # Display datafile\n",
    "    def display_data(self):\n",
    "        self.tarin_file = input(\"Enter the train name:\")\n",
    "\n",
    "        file_exist = os.path.exists(self.train_file)\n",
    "        # Exception Handling for file\n",
    "        try:\n",
    "            f = open(self.train_file, 'rb')\n",
    "            # print(\"File exist\", file_exist)\n",
    "            self.df_1 = pd.read_csv(self.train_file)\n",
    "            print(\"\\n\",self.df)\n",
    "            print(\"\\nType of DF: \",type(self.df_1))\n",
    "            print(\"\\nData type of each column:\\n\",self.df_1.dtypes)\n",
    "            # descibe dataframe\n",
    "            print(\"\\nDescribe Data: \\n\",self.df_1.describe())\n",
    "            \n",
    "        except FileNotFoundError as ex:\n",
    "            print(\"\\nInvalid file Name\",ex)\n",
    "        #############################################################3\n",
    "        self.test_file = input(\"Enter the test name:\")\n",
    "        file_exist = os.path.exists(self.test_file)\n",
    "        # Exception Handling for file\n",
    "        try:\n",
    "            f = open(self.test_file, 'rb')\n",
    "            # print(\"File exist\", file_exist)\n",
    "            self.df_2 = pd.read_csv(self.test_file)\n",
    "            print(\"\\n\",self.df)\n",
    "            print(\"\\nType of DF: \",type(self.df_2))\n",
    "            print(\"\\nData type of each column:\\n\",self.df_2.dtypes)\n",
    "            # descibe dataframe\n",
    "            print(\"\\nDescribe Data: \\n\",self.df_2.describe())\n",
    "            \n",
    "        except FileNotFoundError as ex:\n",
    "            print(\"\\nInvalid file Name\",ex)\n",
    "            \n",
    "        \n",
    "    \"\"\"Handling Missing Data\"\"\"\n",
    "    def missing_data(self):\n",
    "     \n",
    "        # check null values in each column\n",
    "        print(\"Null values in dataset:\\n\",self.df_1.isnull().sum())\n",
    "\n",
    "        self.df_1['x'].replace(np.NaN, self.df['x'].mean(), inplace = True)\n",
    "        # store data into other variable , otherwise put inplace= True to update dataset\n",
    "        self.df_1.y = self.df_1['y'].replace(np.NaN, self.df_1['y'].mean())\n",
    "        # mean= df['Age'].mean()\n",
    "        # df1 = df['Age'].replace(np.NaN,mean)\n",
    "        # print(df1)\n",
    "        print(\"\\n\",self.df_1)\n",
    "        ##########################################3\n",
    "                # check null values in each column\n",
    "        print(\"Null values in dataset:\\n\",self.df_2.isnull().sum())\n",
    "\n",
    "        self.df_2['x'].replace(np.NaN, self.df_2['x'].mean(), inplace = True)\n",
    "        # store data into other variable , otherwise put inplace= True to update dataset\n",
    "        self.df_2.y = self.df_2['y'].replace(np.NaN, self.df_2['y'].mean())\n",
    "        # mean= df['Age'].mean()\n",
    "        # df1 = df['Age'].replace(np.NaN,mean)\n",
    "        # print(df1)\n",
    "        print(\"\\n\",self.df_2)\n",
    "        \n",
    "        \n",
    "\n",
    "    def check_outliers(self):\n",
    "        # check if outliers are present\n",
    "        self.df.boxplot()\n",
    "        plt.show()\n",
    "    \n",
    "    def feature_scaling(self):\n",
    "       \n",
    "        print(\"\\n BY Simple Feature Scalling \")\n",
    "#         self.df['Age']=np.divide(self.df['Age'], self.df.['Age'].max())\n",
    "        self.df_1['x']=self.df_1['x']/self.df_1['x'].max()\n",
    "        self.df['y']=np.divide(self.df_1['y'], self.df_1['y'].max())\n",
    "        print(self.df_1)\n",
    "        \n",
    "#         print(\"\\n By Normalization Method \")\n",
    "#         self.df['x'] = np.divide((self.df['x'] - self.df['x'].min()), (self.df['x'].max() - self.df['x'].min()))\n",
    "#         self.df['y'] = (self.df['y'] - self.df['y'].min())/(self.df['y'].max() - self.df['y'].min())\n",
    "#         print(self.df)\n",
    "                                      \n",
    "#         print(\"\\n By Z score Method \")\n",
    "#         self.df['x'] = np.divide((self.df['x'] - self.df['Age'].mean()), self.df['x'].std())\n",
    "#         self.df['y'] =  np.divide((self.df['y'] - self.df['y'].mean()),self.df['y'].std())\n",
    "#         print(self.df)\n",
    "\n",
    "    def spliting(self):\n",
    "        x_train_data = self.df.x\n",
    "        x_train_data = self.df.x\n",
    "\n",
    "    def gradient_descent(x_train_data,y_train_data):\n",
    "        # to check the number of observation\n",
    "        size = len(x_train_data)\n",
    "        \n",
    "        #epoch loop\n",
    "        for _ in range(self.epoch):\n",
    "            for row in range(size):\n",
    "                hypo1 = self.theta_0 + (self.theta_1 * y_train_data[row])\n",
    "                hypo2 = [( self.theta_0 + self.theta_1 * x_train_data[row] ) - y_train_data] * x_train_data[row]\n",
    "                \n",
    "            self.theta_0 = self.theta_0 - [(self.learning_rate / size) * hypo1]\n",
    "            self.theta_1 = self.theta_1 - [(self.learning_rate / size) * hypo2]\n",
    "            \n",
    "        return [self.theta_0, self.theta_1]\n",
    "    \n",
    "    def predict(x_test_data, theta_00, theta_11 ):\n",
    "        n = len(x_test_data)\n",
    "        vector = np.ones(n)\n",
    "        \n",
    "        for row in range (n):\n",
    "            y_predict[row] = theta_00 + theta_11 * x_test_data[row] + vector[row]\n",
    "            \n",
    "        return y_predict\n",
    "    \n",
    "    def accuracy(y_text_data, y_predict):\n",
    "        diff = 0\n",
    "        for row in range (len(y_text_data)):\n",
    "            diff += abs((y_predict[row] - y_text_data[row]) / y_text_data )\n",
    "            \n",
    "        data_accuracy = diff * 100\n",
    "        return data_accuracy\n",
    "\n",
    "def main():\n",
    "      \n",
    "    #load files\n",
    "    train_data = pd.read_csv(\"train.csv\")\n",
    "    test_data = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "    x_train_data = train_data.x\n",
    "    y_train_data = train_data.y\n",
    "    \n",
    "    x_test_data = test_data.x\n",
    "    y_test_data = test_data.y\n",
    "    \n",
    "#     print(\"\\n----------Show dataset details:----------\")\n",
    "#     obj.display_data()\n",
    "#     print(\"\\n----------Handling Missing Data:----------\")\n",
    "#     obj.missing_data()\n",
    "    \n",
    "#     obj.check_outliers()\n",
    "    \n",
    "#     obj.feature_scaling()\n",
    "    \n",
    "    \n",
    "# class Object created to call its method\n",
    "obj = SimpleLR()\n",
    "# if __name__ == \"__main__\":\n",
    "#         main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
