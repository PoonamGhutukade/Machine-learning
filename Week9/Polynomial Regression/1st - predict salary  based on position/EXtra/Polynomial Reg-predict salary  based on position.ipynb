{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:13:08.258880Z",
     "start_time": "2019-05-01T19:13:08.255275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPolynomial Regression\\n1. Build a machine learning model to predict salary  based on position for a given dataset\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Polynomial Regression\n",
    "1. Build a machine learning model to predict salary  based on position for a given dataset\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T04:36:47.171260Z",
     "start_time": "2019-05-02T04:36:46.145758Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt  \n",
    "import pandas as pd\n",
    "#imputer to handle missing data \n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# handle categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "#regression librarry\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#o check accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "# to check accuracy\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import pickle \n",
    "import os, sys\n",
    "import csv\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T04:37:32.246995Z",
     "start_time": "2019-05-02T04:37:32.200913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Level</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Consultant</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager</td>\n",
       "      <td>4</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country Manager</td>\n",
       "      <td>5</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Position  Level  Salary\n",
       "0   Business Analyst      1   45000\n",
       "1  Junior Consultant      2   50000\n",
       "2  Senior Consultant      3   60000\n",
       "3            Manager      4   80000\n",
       "4    Country Manager      5  110000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset_original = pd.read_csv (\"Position_Salaries.csv\")\n",
    "dataset = dataset_original\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T04:39:38.189528Z",
     "start_time": "2019-05-02T04:39:38.185838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 10 rows and 3 Columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset has {} rows and {} Columns\".format(dataset.shape[0],dataset.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Level</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Position  Level  Salary\n",
       "2  Senior Consultant      3   60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T04:39:40.329806Z",
     "start_time": "2019-05-02T04:39:40.317776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      "Position    10 non-null object\n",
      "Level       10 non-null int64\n",
      "Salary      10 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 320.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# check dataset information\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T04:39:46.099337Z",
     "start_time": "2019-05-02T04:39:46.023913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Level</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.027650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.75</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary</th>\n",
       "      <td>10.0</td>\n",
       "      <td>249500.0</td>\n",
       "      <td>299373.883668</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>65000.00</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>275000.00</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count      mean            std      min       25%       50%  \\\n",
       "Level    10.0       5.5       3.027650      1.0      3.25       5.5   \n",
       "Salary   10.0  249500.0  299373.883668  45000.0  65000.00  130000.0   \n",
       "\n",
       "              75%        max  \n",
       "Level        7.75       10.0  \n",
       "Salary  275000.00  1000000.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T04:39:49.335697Z",
     "start_time": "2019-05-02T04:39:49.326117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Position    0\n",
       "Level       0\n",
       "Salary      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling missing data if nessesary\n",
    "\"\"\"\n",
    "if missing values are present\n",
    "imputer = Imputer(missing_values=0, axis=0)\n",
    "imputer = imputer.fit(x_data[:, 3:16])\n",
    "\"\"\"\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T04:39:51.853440Z",
     "start_time": "2019-05-02T04:39:51.844042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Position    Business Analyst\n",
       "Level                      1\n",
       "Salary                 45000\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for minimum dataset\n",
    "dataset.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks for duplicate values\n",
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['Level','Salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T04:40:07.232915Z",
     "start_time": "2019-05-02T04:40:07.191396Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Handle Missing data\n",
    "# def handle_min_values(dataset):\n",
    "#     # replace min values by mean\n",
    "#     dataset.replace(0, dataset.mean(), inplace=True)\n",
    "#     return dataset\n",
    "\n",
    "# dataset = handle_min_values(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T04:40:53.240716Z",
     "start_time": "2019-05-02T04:40:53.233122Z"
    }
   },
   "outputs": [],
   "source": [
    "# #check dataset replace with mean or not\n",
    "# dataset.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:17:53.754583Z",
     "start_time": "2019-05-01T19:17:53.736752Z"
    }
   },
   "outputs": [],
   "source": [
    "# # seperate fetures and label\n",
    "# x_data = dataset.iloc[:, :-1].values\n",
    "# y_data = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:17:55.464594Z",
     "start_time": "2019-05-01T19:17:55.355917Z"
    }
   },
   "outputs": [],
   "source": [
    "# # handle categorical data\n",
    "# def handle_categorical_data(x_data):\n",
    "#     #encode categorical data\n",
    "#     label_encod = LabelEncoder()\n",
    "#     x_data[:, 1] = label_encod.fit_transform(x_data[:, 1])\n",
    "    \n",
    "#     # one hot encoding\n",
    "#     onehotencode = OneHotEncoder(categorical_features= [1])\n",
    "#     x_data = onehotencode.fit_transform(x_data).toarray()\n",
    "    \n",
    "#     return x_data\n",
    "    \n",
    "# x_data = handle_categorical_data(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:19:11.279465Z",
     "start_time": "2019-05-01T19:19:11.275304Z"
    }
   },
   "outputs": [],
   "source": [
    "# #convert numpy.ndarray to DataFrame\n",
    "# x_data = pd.DataFrame(x_data)\n",
    "# x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to store csv files\n",
    "# os.mkdir(\"CSV_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:18:11.195666Z",
     "start_time": "2019-05-01T19:18:04.320494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (8, 2)  test :  (2, 2)\n",
      "train_data :  (5, 2)  crossV_data :  (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# split dataset \n",
    "\n",
    "def splitdata(dataset):\n",
    "    # split train and test data\n",
    "    train, test = train_test_split(dataset,test_size = 0.20, random_state=0)\n",
    "    print(\"train : \", train.shape, \" test : \", test.shape)\n",
    "\n",
    "    # saving datasets into csv files\n",
    "    test.to_csv('CSV_files/test_file.csv',index=False,encoding='utf-8')\n",
    "\n",
    "    # divide train data into train and cross validation \n",
    "    train_data, crossV_data = train_test_split(train,test_size = 0.30,random_state=0)\n",
    "    \n",
    "     #load data into csv for train and cross validation\n",
    "    train_data.to_csv('CSV_files/train_file.csv',index=False,encoding='utf-8')\n",
    "    crossV_data.to_csv('CSV_files/CValidation_file.csv',index=False,encoding='utf-8')\n",
    "    \n",
    "    print(\"train_data : \", train_data.shape, \" crossV_data : \", crossV_data.shape)\n",
    "\n",
    "splitdata(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:18:11.206852Z",
     "start_time": "2019-05-01T19:18:11.197751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 5 rows and 2 Columns\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "train_dataset = pd.read_csv (\"CSV_files/train_file.csv\")\n",
    "print(\"Dataset has {} rows and {} Columns\".format(train_dataset.shape[0],train_dataset.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:18:11.218060Z",
     "start_time": "2019-05-01T19:18:11.209040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level  Salary\n",
       "0      6  150000\n",
       "1      7  200000\n",
       "2      5  110000\n",
       "3      4   80000\n",
       "4      8  300000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train_dataset.iloc[:,:-1].values\n",
    "# y_train = train_dataset.iloc[:,1].values  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fitting simple linear regression model to the training dataset\n",
    "# # lin_reg = LinearRegression(normalize=True)  \n",
    "# # lin_reg.fit( x_train, y_train)  \n",
    "\n",
    "# # fitting polynomial regression model to the training dataset\n",
    "# poly_reg = PolynomialFeatures(degree=3)\n",
    "# x_poly = poly_reg.fit_transform(x_train)\n",
    "# # fit into multiple Linear regression model\n",
    "# lin_reg2 = LinearRegression()\n",
    "# lin_reg2.fit(x_poly,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:18:11.256290Z",
     "start_time": "2019-05-01T19:18:11.230486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1) (5,)\n",
      "\n",
      "Module created\n",
      "\n",
      "Pikle file created\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PolynomialFeatures' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-91509264ba6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-91509264ba6a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPikle file created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0my_train_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoly_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlin_reg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n y_prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-91509264ba6a>\u001b[0m in \u001b[0;36my_prediction\u001b[0;34m(self, x_train, lin_reg2, poly_reg)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# predicting the train set result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#         y = lin_reg2.predict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0my_pred_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlin_reg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PolynomialFeatures' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "class Polynomial_Reg():\n",
    "    \n",
    "    def reference_module(self,x_train):\n",
    "        # fitting polynomial regression model to the training dataset\n",
    "        poly_reg = PolynomialFeatures(degree=4)\n",
    "        x_poly = poly_reg.fit_transform(x_train)\n",
    "#         x_poly=poly_reg.fit_transform(x_train)\n",
    "        \n",
    "        return poly_reg, x_poly\n",
    "      \n",
    "\n",
    "    def create_module(self,x_train,y_train, x_poly):\n",
    "#         # fitting polynomial regression model to the training dataset\n",
    "#         poly_reg = PolynomialFeatures(degree=4)\n",
    "#         x_poly = poly_reg.fit_transform(x_train)\n",
    "        # fit into multiple Linear regression model\n",
    "        lin_reg2 = LinearRegression()\n",
    "        lin_reg2.fit(x_poly,y_train)\n",
    "\n",
    "        return poly_reg, lin_reg2\n",
    "    \n",
    "    def create_piklefile(self,poly_reg, lin_reg2):\n",
    "        fileObject = open(\"train_data.pkl\",'wb')       \n",
    "        # dump train model pickle file\n",
    "        file = open('Polynomial_RegModule.pkl', 'wb')\n",
    "        pickle.dump(poly_reg,file)\n",
    "        pickle.dump(lin_reg2,file)\n",
    "        # here we close the fileObject\n",
    "        file.close()          \n",
    "        \n",
    "    \n",
    "    def y_prediction(self,x_train,lin_reg2,poly_reg):\n",
    "        # predicting the train set result\n",
    "#         y = lin_reg2.predict()\n",
    "        y_pred_train=lin_reg2.predict(poly_reg.fit_transform(x_train))\n",
    "        return y_pred_train\n",
    "    \n",
    "    def accuracy(self,y_predict_train,y_train):\n",
    "        # accuracy using r2 score\n",
    "        acc_r2 = r2_score(y_train, y_predict_train)*100      \n",
    "#         acc_r2 = (1-error)*100\n",
    "  \n",
    "        total_error = mean_absolute_error(y_train, y_predict_train)\n",
    "        mean_ab=( 1- (total_error / len(y_train))) *100\n",
    "        \n",
    "        mean_sq  = mean_squared_error(y_train, y_predict_train) \n",
    "\n",
    "        mean_sq_log = mean_squared_log_error(y_train, y_predict_train)  \n",
    "    \n",
    "        median_ab_error = median_absolute_error(y_train, y_predict_train)\n",
    "        \n",
    "        return acc_r2,mean_ab,mean_sq,mean_sq_log, median_ab_error\n",
    "    \n",
    "\n",
    "    \n",
    "    def visualization(self,x_train,y_train,poly_reg, lin_reg2):\n",
    "        # Visualization the Decision Tree result (for higher resolution & smoother curve)\n",
    "        x_grid=np.arange(min(x_train),max(x_train),0.1)\n",
    "        x_grid=x_grid.reshape((len(x_grid),1))\n",
    "        \n",
    "        plt.scatter(x_train,y_train,color='red')\n",
    "        plt.plot(x_grid,lin_reg2.predict(poly_reg.fit_transform(x_grid)),color='blue')\n",
    "        plt.title('predict salary  based on position (Training Set)')\n",
    "        plt.xlabel('Level')\n",
    "        plt.ylabel('Salary')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "def main():\n",
    "    #class obj created\n",
    "    obj  = Polynomial_Reg()\n",
    "    \n",
    "    # seperate fetures and label\n",
    "    # here we taking only 2 columns level and salary\n",
    "    x_train = train_dataset.iloc[:,:-1].values\n",
    "    y_train = train_dataset.iloc[:,1].values  \n",
    "    \n",
    "    poly_reg, x_poly = obj.reference_module(x_train)\n",
    "#     y_train = y_train.reshape(-1, 1)\n",
    "    print(x_train.shape, y_train.shape)\n",
    "    poly_reg, lin_reg2 = obj.create_module(x_train,y_train, x_poly)\n",
    "    print(\"\\nModule created\")\n",
    "    \n",
    "    obj.create_piklefile(poly_reg, lin_reg2)\n",
    "    print(\"\\nPikle file created\")\n",
    "    \n",
    "    y_train_pre = obj.y_prediction(x_train,poly_reg, lin_reg2)\n",
    "    print(\"\\n\\n y_prediction:\",y_train_pre)\n",
    "    \n",
    "    acc_r2,mean_ab,mean_sq,mean_sq_log, median_ab_error = obj.accuracy(y_train_pre,y_train)\n",
    "    print(\"\\n Accuracy train by acc_r2\", acc_r2)\n",
    "    print(\"\\n Accuracy train by mean_ab\", mean_ab)\n",
    "    print(\"\\n Accuracy train by mean_sq\", mean_sq)\n",
    "    print(\"\\n Accuracy train by mean_sq_log\", mean_sq_log)\n",
    "    print(\"\\n Accuracy train by median_ab_error\", median_ab_error)\n",
    "    \n",
    "    \n",
    "    \n",
    "    obj.visualization(x_train,y_train, poly_reg, lin_reg2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 3 rows and 2 Columns\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "\n",
    "# load dataset\n",
    "CV_dataset = pd.read_csv (\"CSV_files/CValidation_file.csv\")\n",
    "print(\"Dataset has {} rows and {} Columns\".format(CV_dataset.shape[0],CV_dataset.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #cross validation\n",
    "# file1 = open('SimpleLRModulefile.pkl', 'rb')\n",
    "# reg1 = pickle.load(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " y_prediction: [-210571.42857152  -62000.00000004  698000.        ]\n",
      "\n",
      " Accuracy train by acc_r2 72.0484822514522\n",
      "\n",
      " Accuracy train by median_ab_error 255571.4285715154\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PolynomialFeatures' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-9ad9617ff1f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-9ad9617ff1f2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Accuracy train by median_ab_error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian_ab_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-9ad9617ff1f2>\u001b[0m in \u001b[0;36mvisualization\u001b[0;34m(self, x_cv, y_cv, lin_reg2, poly_reg)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_cv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlin_reg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict salary  based on position (Cross Validation Set)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Level'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PolynomialFeatures' object has no attribute 'predict'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Cross_validation():\n",
    "           \n",
    "    def y_prediction(self,poly_reg, lin_reg2,  x_cv):\n",
    "        # predicting the test set result\n",
    "        y_predict=lin_reg2.predict(poly_reg.fit_transform(x_cv))\n",
    "        return y_predict\n",
    "        \n",
    "#         # predicting the test set result\n",
    "#         return regression.predict(x_train)\n",
    "    \n",
    "    def accuracy(self,y_predict_train,y_train):\n",
    "        # acc using r2\n",
    "        acc_r2 = r2_score(y_train, y_predict_train)*100\n",
    "#         acc_r2 = (1-error)*100\n",
    "        \n",
    "        # using median_ab_error\n",
    "        median_ab_error = median_absolute_error(y_train, y_predict_train)\n",
    "        return acc_r2, median_ab_error\n",
    "    \n",
    "    def visualization(self,x_cv,y_cv, lin_reg2,poly_reg):\n",
    "        # Visualization the Decision Tree result (for higher resolution & smoother curve)\n",
    "         # visualizing the testing set result\n",
    "        x_grid=np.arange(min(x_cv),max(x_cv),0.1)\n",
    "        x_grid=x_grid.reshape((len(x_grid),1))\n",
    "        \n",
    "        plt.scatter(x_cv,y_cv,color='red')\n",
    "        plt.plot(x_grid,lin_reg2.predict(poly_reg.fit_transform(x_grid)),color='blue')\n",
    "        plt.title('predict salary  based on position (Cross Validation Set)')\n",
    "        plt.xlabel('Level')\n",
    "        plt.ylabel('Salary')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "def main():\n",
    "    #class obj created\n",
    "    obj  = Cross_validation()\n",
    "    \n",
    "    # seperate fetures and label\n",
    "    x_cv = CV_dataset.iloc[:,:-1].values\n",
    "    y_cv = CV_dataset.iloc[:,1].values\n",
    " \n",
    "    #     print(x_cv.shape,y_cv.shape)\n",
    "    #cross validation\n",
    "    file1 = open('Polynomial_RegModule.pkl', 'rb')\n",
    "    reg1 = pickle.load(file1)\n",
    "    \n",
    "    # y_prediction ( cross validation)   \n",
    "    y_cv_pre = obj.y_prediction(poly_reg, lin_reg2 , x_cv)\n",
    "    print(\"\\n\\n y_prediction:\",y_cv_pre)\n",
    "    \n",
    "    acc_r2, median_ab_error= obj.accuracy(y_cv_pre,y_cv)\n",
    "    print(\"\\n Accuracy train by acc_r2\", acc_r2)\n",
    "    print(\"\\n Accuracy train by median_ab_error\", median_ab_error)\n",
    "\n",
    "    obj.visualization(x_cv, y_cv, reg1, poly_reg)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here decision tree gives 100% or very small accuracy bcoz of overfitting and small amount of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
